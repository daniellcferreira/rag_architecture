{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo uma Arquitetura RAG Avançada\n"
      ],
      "metadata": {
        "id": "SAPraac0tg6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação das bibliotecas necessárias para o notebook\n",
        "\n",
        "# Biblioteca para usar a API da Groq (modelos de linguagem otimizados para baixa latência)\n",
        "!pip install -q groq\n",
        "\n",
        "# Biblioteca de embeddings pré-treinados para transformar textos em vetores (usada em RAG)\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "# Biblioteca para acessar conteúdos da Wikipedia de forma programática\n",
        "!pip install -q wikipedia-api\n",
        "\n",
        "# Conjunto de bibliotecas do LangChain e ecossistema:\n",
        "# - langchain-nvidia-ai-endpoints: integração com os modelos NIM da NVIDIA\n",
        "# - langchain-community: integrações da comunidade com loaders, embeddings, etc.\n",
        "# - langchain: framework principal para RAG, agentes e pipelines\n",
        "# - langgraph: orquestração de fluxos com grafos de estados\n",
        "# - tavily-python: integração com o motor de busca Tavily\n",
        "# - beautifulsoup4 e lxml: usados para parsing de HTML quando carregamos páginas da web\n",
        "!pip install -qU langchain-nvidia-ai-endpoints langchain-community langchain langgraph tavily-python beautifulsoup4 lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P5e2EolYV-F",
        "outputId": "075e8da5-390e-4a08-fb8b-11af3ff9863f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5s9UiVfSMVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952080b6-875b-455e-f15b-8a2c353e60fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# Bibliotecas padrão do Python\n",
        "import json   # para manipulação de dados no formato JSON\n",
        "import os     # para acesso a variáveis de ambiente e operações do sistema\n",
        "\n",
        "# Bibliotecas numéricas e utilitárias\n",
        "import numpy as np        # cálculos numéricos e vetoriais\n",
        "import operator           # funções utilitárias para operações (ex: itemgetter)\n",
        "\n",
        "# Google Colab\n",
        "from google.colab import userdata   # para acessar dados/segredos do usuário armazenados no Colab\n",
        "\n",
        "# APIs e Modelos\n",
        "from google import genai            # integração com modelos generativos do Google (Gemini, etc.)\n",
        "from groq import Groq               # cliente para usar modelos da Groq (otimização de LLMs)\n",
        "from openai import OpenAI           # cliente oficial para API da OpenAI\n",
        "\n",
        "# Visualização\n",
        "from IPython.display import Image, display   # exibir imagens diretamente no notebook\n",
        "\n",
        "# LangChain - manipulação de texto, dados e fluxos\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # dividir textos longos em chunks\n",
        "from langchain_community.document_loaders import WebBaseLoader      # carregar dados de páginas da web\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults  # integração com motor Tavily\n",
        "from langchain_core.vectorstores import InMemoryVectorStore         # armazenamento vetorial em memória\n",
        "from langchain_core.messages import HumanMessage, SystemMessage     # tipos de mensagens usadas em LLMs\n",
        "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA  # embeddings e chat da NVIDIA NIM\n",
        "from langchain.schema import Document                               # estrutura padrão de documentos no LangChain\n",
        "\n",
        "# LangGraph - orquestração de fluxos de agentes\n",
        "from langgraph.graph import END, StateGraph  # definição de estados e término do grafo\n",
        "\n",
        "# Validação de dados e modelos\n",
        "from pydantic import BaseModel, Field        # validação e definição de schemas de dados\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer  # biblioteca de embeddings da Hugging Face\n",
        "\n",
        "# Tipagem avançada\n",
        "from typing_extensions import TypedDict, List, Annotated, Literal  # anotações de tipos mais sofisticadas\n",
        "\n",
        "# Acesso à Wikipedia\n",
        "from wikipediaapi import Wikipedia   # biblioteca para buscar conteúdos da Wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Como conseguir as API keys?\n",
        "\n",
        "Busque no Google \"Nome da empresa API key\", funciona em 90% das vezes. Todas as API keys abaixo são de planos free."
      ],
      "metadata": {
        "id": "ys9fZpKGSc9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração de variáveis de ambiente para os serviços usados no notebook\n",
        "\n",
        "# Ativa o sistema de tracing da LangChain para monitorar execução de fluxos e agentes\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
        "\n",
        "# Define o endpoint da LangSmith (plataforma de observabilidade da LangChain)\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
        "\n",
        "# Define a chave de API da LangSmith, recuperada dos segredos do Colab\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "\n",
        "# Nome do projeto no LangSmith para organizar logs e execuções\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-crushing-nexus-98\"\n",
        "\n",
        "# Define a chave de API do Tavily (motor de busca inteligente), vinda dos segredos do Colab\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "\n",
        "# Define a chave de API da NVIDIA, também recuperada dos segredos do Colab\n",
        "os.environ[\"NVIDIA_API_KEY\"] = userdata.get(\"NVIDIA_API_KEY\")"
      ],
      "metadata": {
        "id": "5ltdjgSoBGju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de inicialização de diferentes clientes de LLM.\n",
        "# As duas primeiras linhas estão comentadas, mas mostram como seria a conexão\n",
        "# com outros provedores:\n",
        "# - Gemini (Google) usando a chave GEMINI_API_KEY\n",
        "# - OpenAI usando a chave OPENAI_API_KEY\n",
        "\n",
        "# Inicialização do cliente Groq, utilizando a chave armazenada no Colab.\n",
        "client = Groq(api_key=userdata.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "# Definição do modelo a ser usado.\n",
        "# Aqui está selecionado o LLaMA 3.1 de 70B parâmetros.\n",
        "# A linha de baixo é uma alternativa para usar a versão de 8B parâmetros.\n",
        "model_id = \"meta/llama-3.1-70b-instruct\"\n",
        "# model_id = \"meta/llama-3.1-8b-instruct\"\n",
        "\n",
        "# Criação da instância de ChatNVIDIA para chamadas de LLM,\n",
        "# configurada com o modelo escolhido e temperatura 0 (respostas mais determinísticas).\n",
        "llm = ChatNVIDIA(model=model_id, temperature=0)"
      ],
      "metadata": {
        "id": "A7CsiREYZis8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs que servirão como base de conhecimento.\n",
        "# Cada link contém artigos da Lilian Weng sobre agentes, prompt engineering e ataques adversariais em LLMs.\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "# Carregamento dos documentos a partir das URLs usando o WebBaseLoader.\n",
        "# Cada URL retorna uma lista de documentos, por isso é criada uma lista de listas.\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "\n",
        "# Flatten da lista de listas em uma única lista de documentos.\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Criação de um divisor de texto que utiliza o tokenizador do tiktoken.\n",
        "# O texto será quebrado em pedaços de até 250 tokens, sem sobreposição entre eles.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Criação de uma base vetorial em memória a partir dos documentos divididos.\n",
        "# É utilizado o modelo NVIDIA para gerar embeddings (NV-Embed-QA).\n",
        "vectorstore = InMemoryVectorStore.from_documents(\n",
        "    documents=doc_splits,\n",
        "    embedding=NVIDIAEmbeddings(model='NV-Embed-QA'),\n",
        ")\n",
        "\n",
        "# Transformação da base vetorial em um \"retriever\".\n",
        "# O retriever permite buscar os 3 documentos mais relevantes para uma consulta.\n",
        "retriever = vectorstore.as_retriever(k=3)"
      ],
      "metadata": {
        "id": "1N7-HEvwF1_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do schema de saída para o roteador de consultas.\n",
        "# A classe BaseModel (do Pydantic) define que toda consulta deve ser roteada\n",
        "# para uma das duas opções: \"vectorstore\" ou \"websearch\".\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Direcione uma consulta para a fonte de informação mais útil.\"\"\"\n",
        "\n",
        "    # O campo datasource só pode assumir os valores \"vectorstore\" ou \"websearch\".\n",
        "    datasource: Literal[\"vectorstore\", \"websearch\"] = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Dada a pergunta do usuário, escolha encaminhá-la para \"\n",
        "            \"uma pesquisa na web ou para uma vector database.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Configuração do LLM para retornar saídas estruturadas no formato definido pelo Pydantic.\n",
        "# Isso garante que a resposta sempre siga o schema da classe RouteQuery.\n",
        "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "# Prompt do sistema que orienta o modelo a tomar a decisão correta.\n",
        "# Ele explica quando usar a base vetorial (vectorstore) e quando usar a busca na web.\n",
        "router_instructions = \"\"\"Você é especialista em encaminhar a pergunta de um usuário para um vectorstore ou busca na web.\n",
        "O vectorstore contém documentos relacionados a agentes, engenharia de prompts e ataques adversários.\n",
        "Use o vectorstore para perguntas sobre esses tópicos. Para todos os outros, e especialmente para eventos atuais, use a busca na web.\n",
        "Retorna uma saída estruturada com uma única chave, fonte de dados, que pode ser \"websearch\" ou \"vectorstore\", dependendo da pergunta.\"\"\"\n",
        "\n",
        "# Exemplos de testes do roteador:\n",
        "\n",
        "# Exemplo 1: Pergunta sobre campeonato brasileiro → deve usar busca na web\n",
        "test_web_search = structured_llm_router.invoke(\n",
        "    [SystemMessage(content=router_instructions)]\n",
        "    + [\n",
        "        HumanMessage(\n",
        "            content=\"Quem é o favorito para vencer o campeonato brasileiro de 2025?\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Exemplo 2: Pergunta sobre lançamento recente de LLMs → também deve usar busca na web\n",
        "test_web_search_2 = structured_llm_router.invoke(\n",
        "    [SystemMessage(content=router_instructions)]\n",
        "    + [HumanMessage(content=\"Teve algum modelo LLM lançado hoje?\")]\n",
        ")\n",
        "\n",
        "# Exemplo 3: Pergunta sobre memórias de agentes → deve usar vectorstore\n",
        "test_vector_store = structured_llm_router.invoke(\n",
        "    [SystemMessage(content=router_instructions)]\n",
        "    + [HumanMessage(content=\"Quais são os tipos de memórias de agentes?\")]\n",
        ")\n",
        "\n",
        "# Exibe os resultados de cada teste de roteamento\n",
        "print(\n",
        "    test_web_search,\n",
        "    test_web_search_2,\n",
        "    test_vector_store,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GtIG6Oe38Po",
        "outputId": "8d43c7fa-0f71-4c4d-9259-36d8e3df0e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='websearch' datasource='websearch' datasource='vectorstore'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliador de Retrieval"
      ],
      "metadata": {
        "id": "oAQt-CHsDve2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição de um modelo de dados Pydantic para padronizar a resposta do avaliador de relevância.\n",
        "# Essa classe especifica que a resposta deve conter apenas uma chave: binary_score,\n",
        "# cujo valor deve ser \"yes\" ou \"no\".\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Classificação binária para a verificação de relevância dos documentos recuperados.\n",
        "    \"\"\"\n",
        "\n",
        "    # Campo obrigatório que define a classificação do documento\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "# Configuração do LLM para retornar saídas estruturadas no formato GradeDocuments.\n",
        "# Isso garante que a resposta do modelo siga o schema definido.\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Instruções para o avaliador (prompt de sistema).\n",
        "# O modelo deve atuar como um juiz que avalia a relevância de documentos recuperados\n",
        "# em relação à pergunta do usuário.\n",
        "doc_grader_instructions = \"\"\"Você é um avaliador que avalia a relevância de um documento recuperado para a pergunta de um usuário.\n",
        "Se o documento contiver palavras-chave ou significado semântico relacionado à pergunta, classifique-o como relevante.\"\"\"\n",
        "\n",
        "# Prompt de avaliação, formatado com placeholders para o documento e a pergunta.\n",
        "# O modelo deve verificar se há pelo menos alguma relação entre eles.\n",
        "doc_grader_prompt = \"\"\"Aqui está o documento recuperado: \\n\\n {document} \\n\\n Aqui está a pergunta do usuário: \\n\\n {question}.\n",
        "\n",
        "Avalie cuidadosa e objetivamente se o documento contém pelo menos alguma informação relevante para a pergunta.\n",
        "Retorne uma saída estruturada com uma única chave, binary_score, que é uma classificação \"yes\" ou \"no\" para indicar se o documento\n",
        "contém pelo menos alguma informação relevante para a pergunta\n",
        "\"\"\"\n",
        "\n",
        "# ----------------\n",
        "# Testando o avaliador\n",
        "# ----------------\n",
        "\n",
        "# Pergunta de teste do usuário\n",
        "question = \"O que é prompt do tipo chain-of-thought?\"\n",
        "\n",
        "# Recupera documentos da base vetorial relacionados à pergunta\n",
        "docs = retriever.invoke(question)\n",
        "\n",
        "# Seleciona o conteúdo de um dos documentos recuperados\n",
        "doc_txt = docs[1].page_content\n",
        "\n",
        "# Substitui placeholders no prompt pelo documento e pela pergunta\n",
        "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
        "    document=doc_txt, question=question\n",
        ")\n",
        "\n",
        "# Invoca o avaliador (LLM) passando:\n",
        "# - as instruções do avaliador (SystemMessage)\n",
        "# - o prompt formatado com documento e pergunta (HumanMessage)\n",
        "result = structured_llm_grader.invoke(\n",
        "    [SystemMessage(content=doc_grader_instructions)]\n",
        "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
        ")\n",
        "\n",
        "# Exibe o resultado (esperado: {'binary_score': 'yes'} ou {'binary_score': 'no'})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUYaJwjt4Awu",
        "outputId": "d7cb39f7-3499-4f00-86f4-97f8c6ae8f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeDocuments(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração de resposta pelo LLM"
      ],
      "metadata": {
        "id": "KsSZEv5LEyp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt contextualizado usando RAG\n",
        "# O prompt instrui o LLM a usar apenas o contexto fornecido para responder,\n",
        "# pensar cuidadosamente e ser conciso (máx. 3 frases).\n",
        "rag_prompt = \"\"\"Você é um assistente para tarefas de resposta a perguntas.\n",
        "Aqui está o contexto a ser usado para responder à pergunta:\n",
        "{context}\n",
        "\n",
        "Pense cuidadosamente sobre o contexto acima.\n",
        "Agora, revise a pergunta do usuário:\n",
        "{question}\n",
        "\n",
        "Responda a esta pergunta usando apenas o contexto acima.\n",
        "Use no máximo três frases e seja conciso.\n",
        "\n",
        "Resposta:\"\"\"\n",
        "\n",
        "# Formatação da resposta\n",
        "# Concatena o conteúdo textual (page_content) de cada Document em uma string única,\n",
        "# separando documentos por duas quebras de linha para manter clareza.\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Testando\n",
        "# Recupera os documentos mais relevantes usando o retriever (assume que `question` existe)\n",
        "docs = retriever.invoke(question)\n",
        "\n",
        "# Converte a lista de Document em texto para inserir no prompt\n",
        "docs_txt = format_docs(docs)\n",
        "\n",
        "# Substitui os placeholders do prompt com o contexto e a pergunta\n",
        "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
        "\n",
        "# Chama o LLM passando a mensagem do usuário contendo o prompt pronto\n",
        "# (dependendo do wrapper, você pode também incluir um SystemMessage com instruções do sistema)\n",
        "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
        "\n",
        "# Imprime o conteúdo gerado pelo modelo\n",
        "print(generation.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s89FbeLQ4Glz",
        "outputId": "91577261-e450-4fbe-e33a-916f8a0e030c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain of thought (CoT) prompting is a technique that generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. This technique is particularly beneficial for complicated reasoning tasks, especially when using large models with more than 50B parameters. CoT prompting helps to decompose hard tasks into smaller and simpler steps, making it easier for the model to arrive at a solution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliador de Alucinação"
      ],
      "metadata": {
        "id": "xRKKv0nNFJ6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define um modelo de dados Pydantic para classificar se uma resposta contém alucinações\n",
        "# (informações não fundamentadas nos fatos fornecidos)\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Classificação binária para alucinação presente na resposta gerada.\"\"\"\n",
        "\n",
        "    # Campo obrigatório que indica se a resposta segue os fatos ('yes') ou contém alucinações ('no')\n",
        "    binary_score: str = Field(\n",
        "        description=\"A resposta está de acordo com os fatos, 'yes' ou 'no'\"\n",
        "    )\n",
        "\n",
        "# Configura o LLM para retornar saídas estruturadas conforme o schema definido\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Instruções detalhadas para o avaliador (prompt de sistema)\n",
        "# Ensina o LLM a atuar como um professor corrigindo se a resposta do \"aluno\" segue os fatos\n",
        "hallucination_grader_instructions = \"\"\"\n",
        "Você é um professor corrigindo um teste. Você receberá os Fatos e uma Resposta do Estudante.\n",
        "\n",
        "Aqui estão os critérios de avaliação a serem seguidos:\n",
        "\n",
        "(1) Certifique-se de que a Resposta do Estudante esteja fundamentada nos Fatos.\n",
        "(2) Certifique-se de que a Resposta do Estudante não contenha informações \"alucinadas\" fora do escopo dos Fatos.\n",
        "\n",
        "Classificação:\n",
        "\n",
        "Uma classificação \"yes\" significa que a resposta do aluno atende a todos os critérios. Esta é a classificação mais alta (melhor).\n",
        "Uma classificação \"no\" significa que a resposta do aluno não atende a todos os critérios. Esta é a classificação mais baixa que você pode dar.\n",
        "Explique seu raciocínio passo a passo para garantir que seu raciocínio e conclusão estejam corretos.\n",
        "Evite simplesmente declarar a resposta correta logo no início.\"\"\"\n",
        "\n",
        "# Prompt de avaliação, formatado com placeholders para os documentos (fatos) e a geração do modelo\n",
        "# O LLM deve retornar uma classificação binária indicando se a resposta está fundamentada nos fatos\n",
        "hallucination_grader_prompt = \"\"\"Fatos: \\n\\n {documents} \\n\\n Resposta do estudante: {generation}.\n",
        "Retorne a saída estruturada com duas chaves, binary_score é uma classificação 'yes' ou 'no' para indicar se a Resposta do Estudante está baseada nos Fatos.\"\"\"\n",
        "\n",
        "# Substitui placeholders no prompt com os documentos reais e a resposta gerada pelo LLM\n",
        "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
        "    documents=docs_txt, generation=generation.content\n",
        ")\n",
        "\n",
        "# Invoca o LLM para avaliar se a resposta contém alucinações, passando:\n",
        "# - instruções do avaliador (SystemMessage)\n",
        "# - prompt formatado com fatos e resposta do estudante (HumanMessage)\n",
        "result = structured_llm_grader.invoke(\n",
        "    [SystemMessage(content=hallucination_grader_instructions)]\n",
        "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
        ")\n",
        "\n",
        "# Exibe o resultado da avaliação (esperado: {'binary_score': 'yes'} ou {'binary_score': 'no'})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRCYVL584Jzb",
        "outputId": "db996a77-12ef-49f4-c810-cc19325e15ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeDocuments(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliador de Resposta Final"
      ],
      "metadata": {
        "id": "T07Gr6I8GQBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define um modelo de dados Pydantic para classificar se a resposta do estudante responde à pergunta\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Classificação binária para avaliar se a resposta corresponde à pergunta.\"\"\"\n",
        "\n",
        "    # Campo obrigatório que indica se a resposta atende à pergunta ('yes') ou não ('no')\n",
        "    binary_score: str = Field(\n",
        "        description=\"Resposta de fato responde a pergunta, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "# Configura o LLM para retornar saídas estruturadas conforme o schema definido\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "# Instruções detalhadas para o avaliador (prompt de sistema)\n",
        "# Ensina o LLM a atuar como um professor corrigindo se a resposta do aluno responde à pergunta\n",
        "answer_grader_instructions = \"\"\"Você é um professor corrigindo um teste. Você receberá uma PERGUNTA e uma RESPOSTA DO ESTUDANTE.\n",
        "\n",
        "Aqui estão os critérios de avaliação a serem seguidos:\n",
        "\n",
        "(1) A RESPOSTA DO ESTUDANTE ajuda a responder à PERGUNTA\n",
        "\n",
        "Classificação:\n",
        "Uma classificação \"yes\" significa que a RESPOSTA DO ESTUDANTE atende a todos os critérios. Esta é a classificação mais alta (melhor).\n",
        "O aluno pode receber uma classificação \"yes\" se a resposta contiver informações adicionais que não sejam explicitamente solicitadas na pergunta.\n",
        "Uma classificação \"no\" significa que a RESPOSTA DO ESTUDANTE não atende a todos os critérios. Esta é a classificação mais baixa que você pode dar.\n",
        "Explique seu raciocínio passo a passo para garantir que seu raciocínio e conclusão estejam corretos.\n",
        "Evite simplesmente declarar a resposta correta logo no início.\"\"\"\n",
        "\n",
        "# Prompt de avaliação, formatado com placeholders para a pergunta e a resposta do estudante\n",
        "# O LLM deve retornar uma saída binária indicando se a resposta atinge os critérios\n",
        "answer_grader_prompt = \"\"\"PERGUNTA: \\n\\n {question} \\n\\n RESPOSTA DO ESTUDANTE: {generation}.\n",
        "Returne uma structured output com binary_score sendo 'yes' ou 'no' indicando se a RESPOSTA DO ESTUDANTE atinge os critérios.\"\"\"\n",
        "\n",
        "# Substitui placeholders no prompt com a pergunta real e a resposta fornecida\n",
        "question = \"Quais modelos da série Llama 3.2 foram lançados por último?\"\n",
        "answer = \"Os modelos Llama 3.2 lançados por último incluem dois modelos de visão: Llama 3.2 11B Vision Instruct e Llama 3.2 90B Vision Instruct. Esses modelos fazem parte da primeira incursão da Meta em IA multimodal e rivalizam com modelos fechados como o Claude 3 Haiku da Anthropic e o GPT-4o mini da OpenAI em raciocínio visual. Eles substituem os antigos modelos Llama 3.1 de texto.\"\n",
        "\n",
        "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
        "    question=question, generation=answer\n",
        ")\n",
        "\n",
        "# Invoca o LLM para avaliar se a resposta corresponde à pergunta, passando:\n",
        "# - instruções do avaliador (SystemMessage)\n",
        "# - prompt formatado com pergunta e resposta (HumanMessage)\n",
        "result = structured_llm_grader.invoke(\n",
        "    [SystemMessage(content=answer_grader_instructions)]\n",
        "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
        ")\n",
        "\n",
        "# Exibe o resultado da avaliação (esperado: {'binary_score': 'yes'} ou {'binary_score': 'no'})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4r1mJOt4MS0",
        "outputId": "ac97de0c-7c1f-4014-8063-6ad1952b865d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeAnswer(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciação do mecanismo de busca Tavily com limite de 3 resultados\n",
        "web_search_tool = TavilySearchResults(k=3)\n",
        "\n",
        "# Definição do estado do grafo como um dicionário tipado (TypedDict)\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Representa o estado de cada nó no grafo, contendo informações\n",
        "    que serão propagadas e modificadas durante o processamento.\n",
        "    \"\"\"\n",
        "\n",
        "    question: str  # Pergunta do usuário\n",
        "    generation: str  # Resposta gerada pelo LLM\n",
        "    web_search: str  # Decisão binária para realizar busca na web\n",
        "    max_retries: int  # Número máximo de tentativas para gerar uma resposta\n",
        "    answers: int  # Contador de respostas geradas\n",
        "    loop_step: Annotated[int, operator.add]  # Contador de etapas no loop\n",
        "    documents: List[str]  # Lista de documentos recuperados"
      ],
      "metadata": {
        "id": "3Q2knOpK_X2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Nodes\n",
        "\n",
        "# Nó responsável por recuperar documentos do vectorstore\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Recupera documentos relevantes da base vetorial com base na pergunta do usuário.\n",
        "    Adiciona os documentos recuperados ao estado do grafo.\n",
        "    \"\"\"\n",
        "    print(\"---RECUPERAR---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents}\n",
        "\n",
        "\n",
        "# Nó responsável por gerar uma resposta usando RAG\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Gera uma resposta do LLM baseada nos documentos recuperados.\n",
        "    Atualiza o estado do grafo com a resposta gerada e incrementa o passo do loop.\n",
        "    \"\"\"\n",
        "    print(\"---GERAR---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    loop_step = state.get(\"loop_step\", 0)\n",
        "\n",
        "    docs_txt = format_docs(documents)\n",
        "    rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
        "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
        "    return {\"generation\": generation, \"loop_step\": loop_step + 1}\n",
        "\n",
        "\n",
        "# Nó que avalia a relevância dos documentos recuperados\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Avalia cada documento recuperado para verificar se é relevante para a pergunta.\n",
        "    Filtra documentos irrelevantes e define uma flag 'web_search' se algum documento não for relevante.\n",
        "    \"\"\"\n",
        "    print(\"---CHECANDO RELEVÂNCIA DO DOCUMENTO PARA A QUESTÃO---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    filtered_docs = []\n",
        "    web_search = \"No\"\n",
        "    structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "    for d in documents:\n",
        "        doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
        "            document=d.page_content, question=question\n",
        "        )\n",
        "\n",
        "        result = structured_llm_grader.invoke(\n",
        "            [SystemMessage(content=doc_grader_instructions)]\n",
        "            + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
        "        )\n",
        "        grade = result.binary_score\n",
        "        if grade.lower() == \"yes\":\n",
        "            print(\"---AVALIAÇÃO: DOCUMENTO RELEVANTE---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---AVALIAÇÃO: DOCUMENTO NÃO É RELEVANTE---\")\n",
        "            web_search = \"Yes\"\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n",
        "\n",
        "\n",
        "# Nó que realiza busca na web se necessário\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Executa uma busca na web com base na pergunta do usuário.\n",
        "    Adiciona os resultados da busca ao conjunto de documentos do estado.\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state.get(\"documents\", [])\n",
        "\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "    return {\"documents\": documents}\n",
        "\n",
        "\n",
        "### Edges\n",
        "\n",
        "# Nó que roteia a pergunta para RAG ou busca na web\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Decide se a pergunta deve ser enviada para o vectorstore (RAG) ou para busca na web.\n",
        "    Baseado na decisão do LLM de roteamento.\n",
        "    \"\"\"\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    structured_llm_router = llm.with_structured_output(RouteQuery)\n",
        "    route_question = structured_llm_router.invoke(\n",
        "        [SystemMessage(content=router_instructions)]\n",
        "        + [HumanMessage(content=state[\"question\"])]\n",
        "    )\n",
        "    source = route_question.datasource\n",
        "    if source == \"websearch\":\n",
        "        print(\"---ROTEAR QUESTÃO PARA BUSCA NA WEB---\")\n",
        "        return \"websearch\"\n",
        "    elif source == \"vectorstore\":\n",
        "        print(\"---ROTEAR QUESTÃO PARA O RAG---\")\n",
        "        return \"vectorstore\"\n",
        "\n",
        "\n",
        "# Nó que decide se devemos gerar resposta ou realizar busca na web\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determina se a resposta deve ser gerada pelo LLM ou se é necessário buscar na web.\n",
        "    Baseado na relevância dos documentos filtrados.\n",
        "    \"\"\"\n",
        "    print(\"---OBSERVAÇÃO DE DOCUMENTOS AVALIADOS---\")\n",
        "    web_search_flag = state[\"web_search\"]\n",
        "\n",
        "    if web_search_flag == \"Yes\":\n",
        "        print(\"---DECISÃO: NEM TODOS OS DOCUMENTOS SÃO RELEVANTES, INCLUIR PESQUISA NA WEB---\")\n",
        "        return \"websearch\"\n",
        "    else:\n",
        "        print(\"---DECISÃO: GERAR---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "# Nó que avalia se a geração do LLM está baseada nos documentos e responde à pergunta\n",
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"\n",
        "    Avalia se a resposta gerada pelo LLM:\n",
        "    1. Está fundamentada nos documentos (sem alucinações)\n",
        "    2. Responde efetivamente à pergunta do usuário\n",
        "\n",
        "    Retorna qual deve ser o próximo nó a ser chamado:\n",
        "    - 'useful' se a resposta estiver correta e baseada nos fatos\n",
        "    - 'not useful' se não responder à pergunta\n",
        "    - 'not supported' se não estiver baseada nos fatos\n",
        "    - 'max retries' se o número máximo de tentativas foi atingido\n",
        "    \"\"\"\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "    max_retries = state.get(\"max_retries\", 3)\n",
        "\n",
        "    hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
        "        documents=format_docs(documents), generation=generation.content\n",
        "    )\n",
        "    structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "    result = structured_llm_grader.invoke(\n",
        "        [SystemMessage(content=hallucination_grader_instructions)]\n",
        "        + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
        "    )\n",
        "    grade = result.binary_score\n",
        "\n",
        "    if grade == \"yes\":\n",
        "        print(\"---DECISÃO: GERAÇÃO ESTÁ BASEADA NOS FATOS---\")\n",
        "        print(\"---AVALIAÇÃO GERAÇÃO vs QUESTÃO---\")\n",
        "        answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
        "            question=question, generation=generation.content\n",
        "        )\n",
        "        structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "        result = structured_llm_grader.invoke(\n",
        "            [SystemMessage(content=answer_grader_instructions)]\n",
        "            + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
        "        )\n",
        "        grade = result.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---DECISÃO: GERAÇÃO RESPONDE A PERGUNTA---\")\n",
        "            return \"useful\"\n",
        "        elif state[\"loop_step\"] <= max_retries:\n",
        "            print(\"---DECISÃO: GERAÇÃO NÃO RESPONDE A PERGUNTA---\")\n",
        "            return \"not useful\"\n",
        "        else:\n",
        "            print(\"---DECISÃO: MÁXIMO DE TENTATIVAS ATINGIDO---\")\n",
        "            return \"max retries\"\n",
        "    elif state[\"loop_step\"] <= max_retries:\n",
        "        print(\"---DECISÃO: GERAÇÃO NÃO ESTÁ BASEADA NOS FATOS, TENTAR NOVAMENTE---\")\n",
        "        return \"not supported\"\n",
        "    else:\n",
        "        print(\"---DECISÃO: MÁXIMO DE TENTATIVAS ATINGIDO---\")\n",
        "        return \"max retries\""
      ],
      "metadata": {
        "id": "L_YaAWVP4pi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do grafo de estados usando a classe StateGraph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Adiciona os nós do grafo com suas respectivas funções\n",
        "workflow.add_node(\"websearch\", web_search)            # Nó para busca na web\n",
        "workflow.add_node(\"retrieve\", retrieve)              # Nó para recuperar documentos do vectorstore\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # Nó para avaliar relevância dos documentos\n",
        "workflow.add_node(\"generate\", generate)              # Nó para gerar resposta usando RAG\n",
        "\n",
        "# Define o ponto de entrada condicional, roteando a pergunta para web ou vectorstore\n",
        "workflow.set_conditional_entry_point(\n",
        "    route_question,\n",
        "    {\n",
        "        \"websearch\": \"websearch\",      # Se roteador decidir websearch, entra no nó 'websearch'\n",
        "        \"vectorstore\": \"retrieve\",     # Se roteador decidir vectorstore, entra no nó 'retrieve'\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define as transições simples entre os nós\n",
        "workflow.add_edge(\"websearch\", \"generate\")  # Após buscar na web, gera resposta\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")  # Após recuperar documentos, avalia relevância\n",
        "\n",
        "# Define transições condicionais após avaliação dos documentos\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"websearch\": \"websearch\",  # Se documentos irrelevantes, fazer busca na web\n",
        "        \"generate\": \"generate\",    # Se documentos relevantes, gerar resposta\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define transições condicionais após geração da resposta\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"not supported\": \"generate\",  # Geração não baseada em fatos, tentar novamente\n",
        "        \"useful\": END,                 # Resposta útil, fim do fluxo\n",
        "        \"not useful\": \"websearch\",     # Resposta não útil, realizar busca na web\n",
        "        \"max retries\": END,            # Máximo de tentativas atingido, fim do fluxo\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compila o grafo e exibe visualmente usando Mermaid\n",
        "graph = workflow.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ],
      "metadata": {
        "id": "FOyw-bMUL2Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a entrada inicial para o grafo de workflow\n",
        "inputs = {\n",
        "    \"question\": \"Quais são os tipos de memória de agentes?\",  # Pergunta do usuário\n",
        "    \"max_retries\": 3  # Número máximo de tentativas para gerar uma resposta válida\n",
        "}\n",
        "\n",
        "# Executa o grafo de forma interativa (streaming), exibindo os eventos à medida que ocorrem\n",
        "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
        "    print(event)  # Imprime cada atualização do estado do grafo durante a execução"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV2ic3-B4vuO",
        "outputId": "2b3ca98c-f28f-49b6-f5cc-965946a2a3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO RAG---\n",
            "{'question': 'What are the types of agent memory?', 'max_retries': 3, 'loop_step': 0}\n",
            "---RETRIEVE---\n",
            "{'question': 'What are the types of agent memory?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(id='3d406e2f-0927-42a9-bee2-7e811ffab2fd', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'), Document(id='58bc3f6f-1cf2-4313-babb-5d203a275a64', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'), Document(id='ba4a36ff-c502-4287-a0b5-1e71925f3d7d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(id='dd7741cd-4309-4e73-88d0-f9dc780d1f07', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions')]}\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: NOT ALL DOCUMENTS ARE RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
            "{'question': 'What are the types of agent memory?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(id='58bc3f6f-1cf2-4313-babb-5d203a275a64', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'), Document(id='ba4a36ff-c502-4287-a0b5-1e71925f3d7d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(id='dd7741cd-4309-4e73-88d0-f9dc780d1f07', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions')]}\n",
            "---WEB SEARCH---\n",
            "{'question': 'What are the types of agent memory?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(id='58bc3f6f-1cf2-4313-babb-5d203a275a64', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'), Document(id='ba4a36ff-c502-4287-a0b5-1e71925f3d7d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(id='dd7741cd-4309-4e73-88d0-f9dc780d1f07', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={}, page_content='How These Work Together in Agentic AI\\n=====================================\\n\\nIn an agentic AI system, these memory types collaborate to create a capable, goal-driven agent. Short-term memory handles immediate demands, while long-term memory — encompassing semantic, episodic, and procedural elements — builds a deeper foundation.\\n\\nSemantic memory provides the facts, episodic memory offers lessons from experience, and procedural memory ensures smooth execution. [...] Episodic memory is the AI’s record of specific experiences or events, tied to a time and context. Think of it as the agent’s personal history — like recalling, “Last Tuesday, I helped a user debug code and got stuck on a syntax error.” In agentic AI, episodic memory allows the system to reflect on past interactions or actions, learning from successes or mistakes. This type of memory adds a narrative layer, helping the AI adjust its behavior based on what it has directly encountered. [...] Long-term memory serves as the AI’s repository for knowledge accumulated over time. Unlike short-term memory, it’s designed to persist, storing information that the agent can revisit later. In agentic AI, long-term memory might include learned patterns, past experiences, or external data it has been trained on. For instance, an AI that remembers how it solved a complex query last week can apply that knowledge to a similar problem today. It’s the foundation for growth and adaptability, allowing\\nResearchers categorize agentic memory in much the same way that psychologists categorize human memory. The influential Cognitive Architectures for Language Agents (CoALA) paper1 from a team at Princeton University describes different types of memory as:\\n\\n### Short-term memory\\n\\nShort-term memory (STM) enables an AI agent to remember recent inputs for immediate decision-making. This type of memory is useful in conversational AI, where maintaining context across multiple exchanges is required. [...] AI agents typically implement semantic memory using knowledge bases, symbolic AI or vector embeddings, allowing them to process and retrieve relevant information efficiently. This type of memory is used in real-world applications that require domain expertise, such as legal AI assistants, medical diagnostic tools and enterprise knowledge management systems.\\n\\n For example, an AI legal assistant can use its knowledge base to retrieve case precedents and provide accurate legal advice. [...] Episodic memory allows AI agents to recall specific past experiences, similar to how humans remember individual events. This type of memory is useful for case-based reasoning, where an AI learns from past events to make better decisions in the future.\\n\\n Episodic memory is often implemented by logging key events, actions and their outcomes in a structured format that the agent can access when making decisions.\\nTherefore, designing an agent\\'s memory is essentially context engineering: determining which tokens enter the context window and how they\\'re organized. Memory systems compose multiple techniques (such as summarization, context rewriting, and retrieval) to manage various memory components (messages, memory blocks, and external databases).\\n\\n## Types of Agent Memory\\n\\nAgent memory systems typically consist of several distinct components, each serving different purposes: [...] An agent\\'s “short-term” memory consists of whatever resides in the message buffer, as this content will eventually be evicted. All other memory types qualify as \"long-term.\" However, it\\'s more helpful to conceptualize agent memory as context engineering: understanding what is or isn\\'t in the context window, and how tokens are pulled back into the context window. Ultimately, memory is about choosing which tokens to place in your context window at any given moment.\\n\\n## Conclusion [...] Memory can also be stored in external databases and retrieved via tool calling. Different storage and retrieval mechanisms suit different applications:\\n\\n Vector DBs: Memories are saved, embedded, and queried via vector search\\n Graph DBs: Memories form graph structures where agents can traverse relationships between concepts, enabling sophisticated reasoning about connected information\\n\\nWhile retrieval (or RAG) is a tool for agent memory, it is not “memory” in of itself.\\nTypes of Memory in Letta\\n------------------------\\n\\nLetta agents have access to multiple memory systems:\\n\\n### Core Memory (In-Context)\\n\\nFast, always-accessible memory that stays in the agent’s context window. This includes:\\n\\n   Persona: The agent’s personality and role\\n   Human: Information about the user\\n   Custom memory blocks: Additional structured information\\n\\n### External Memory (Out-of-Context)\\n\\nLong-term storage for large amounts of information: [...] Additional Resources \\n       Letta Desktop Troubleshooting\\n       ADE Troubleshooting\\n\\nLaunch ADE\\n\\nLight\\n\\nOn this page\\n\\n   The MemGPT Approach to Memory\\n   Types of Memory in Letta\\n   Core Memory (In-Context)\\n   External Memory (Out-of-Context)\\n   Why Agent Memory Matters\\n   Memory Management in Practice\\n\\nStateful Agents\\n\\nAgent Memory\\n============\\n\\nCopy page\\n\\nWhat is agent memory, and how does it work? [...] Automatic management: Agents intelligently decide what to remember\\n   Manual control: Developers can directly view and modify memory blocks\\n   Shared memory: Multiple agents can access common memory blocks\\n   External data sources: Connect agents to files, databases, and APIs\\n\\nMemory blocks are the fundamental units of Letta’s memory system - they can be modified by the agent itself, other agents, or developers through the API.\\n\\nWas this page helpful?\\n\\nYes No\\nThis is lame. We’re better than this (no hate to Langchain, we’re just not in early 2023 anymore).\\n\\nAdvanced Single Agent Memory\\n============================ [...] Vanilla Single Agent Memory\\n===========================')]}\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "{'question': 'What are the types of agent memory?', 'generation': AIMessage(content='According to the context, there are two main types of agent memory: short-term memory and long-term memory. Short-term memory handles immediate demands, while long-term memory encompasses semantic, episodic, and procedural elements. Long-term memory can be further divided into core memory (in-context) and external memory (out-of-context), with external memory including vector databases and graph databases.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'According to the context, there are two main types of agent memory: short-term memory and long-term memory. Short-term memory handles immediate demands, while long-term memory encompasses semantic, episodic, and procedural elements. Long-term memory can be further divided into core memory (in-context) and external memory (out-of-context), with external memory including vector databases and graph databases.', 'token_usage': {'prompt_tokens': 1716, 'total_tokens': 1791, 'completion_tokens': 75}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run--f7ad5d4e-16ba-49c7-8bf6-bb2dc042ff29-0', usage_metadata={'input_tokens': 1716, 'output_tokens': 75, 'total_tokens': 1791}, role='assistant'), 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 1, 'documents': [Document(id='58bc3f6f-1cf2-4313-babb-5d203a275a64', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'), Document(id='ba4a36ff-c502-4287-a0b5-1e71925f3d7d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(id='dd7741cd-4309-4e73-88d0-f9dc780d1f07', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={}, page_content='How These Work Together in Agentic AI\\n=====================================\\n\\nIn an agentic AI system, these memory types collaborate to create a capable, goal-driven agent. Short-term memory handles immediate demands, while long-term memory — encompassing semantic, episodic, and procedural elements — builds a deeper foundation.\\n\\nSemantic memory provides the facts, episodic memory offers lessons from experience, and procedural memory ensures smooth execution. [...] Episodic memory is the AI’s record of specific experiences or events, tied to a time and context. Think of it as the agent’s personal history — like recalling, “Last Tuesday, I helped a user debug code and got stuck on a syntax error.” In agentic AI, episodic memory allows the system to reflect on past interactions or actions, learning from successes or mistakes. This type of memory adds a narrative layer, helping the AI adjust its behavior based on what it has directly encountered. [...] Long-term memory serves as the AI’s repository for knowledge accumulated over time. Unlike short-term memory, it’s designed to persist, storing information that the agent can revisit later. In agentic AI, long-term memory might include learned patterns, past experiences, or external data it has been trained on. For instance, an AI that remembers how it solved a complex query last week can apply that knowledge to a similar problem today. It’s the foundation for growth and adaptability, allowing\\nResearchers categorize agentic memory in much the same way that psychologists categorize human memory. The influential Cognitive Architectures for Language Agents (CoALA) paper1 from a team at Princeton University describes different types of memory as:\\n\\n### Short-term memory\\n\\nShort-term memory (STM) enables an AI agent to remember recent inputs for immediate decision-making. This type of memory is useful in conversational AI, where maintaining context across multiple exchanges is required. [...] AI agents typically implement semantic memory using knowledge bases, symbolic AI or vector embeddings, allowing them to process and retrieve relevant information efficiently. This type of memory is used in real-world applications that require domain expertise, such as legal AI assistants, medical diagnostic tools and enterprise knowledge management systems.\\n\\n For example, an AI legal assistant can use its knowledge base to retrieve case precedents and provide accurate legal advice. [...] Episodic memory allows AI agents to recall specific past experiences, similar to how humans remember individual events. This type of memory is useful for case-based reasoning, where an AI learns from past events to make better decisions in the future.\\n\\n Episodic memory is often implemented by logging key events, actions and their outcomes in a structured format that the agent can access when making decisions.\\nTherefore, designing an agent\\'s memory is essentially context engineering: determining which tokens enter the context window and how they\\'re organized. Memory systems compose multiple techniques (such as summarization, context rewriting, and retrieval) to manage various memory components (messages, memory blocks, and external databases).\\n\\n## Types of Agent Memory\\n\\nAgent memory systems typically consist of several distinct components, each serving different purposes: [...] An agent\\'s “short-term” memory consists of whatever resides in the message buffer, as this content will eventually be evicted. All other memory types qualify as \"long-term.\" However, it\\'s more helpful to conceptualize agent memory as context engineering: understanding what is or isn\\'t in the context window, and how tokens are pulled back into the context window. Ultimately, memory is about choosing which tokens to place in your context window at any given moment.\\n\\n## Conclusion [...] Memory can also be stored in external databases and retrieved via tool calling. Different storage and retrieval mechanisms suit different applications:\\n\\n Vector DBs: Memories are saved, embedded, and queried via vector search\\n Graph DBs: Memories form graph structures where agents can traverse relationships between concepts, enabling sophisticated reasoning about connected information\\n\\nWhile retrieval (or RAG) is a tool for agent memory, it is not “memory” in of itself.\\nTypes of Memory in Letta\\n------------------------\\n\\nLetta agents have access to multiple memory systems:\\n\\n### Core Memory (In-Context)\\n\\nFast, always-accessible memory that stays in the agent’s context window. This includes:\\n\\n   Persona: The agent’s personality and role\\n   Human: Information about the user\\n   Custom memory blocks: Additional structured information\\n\\n### External Memory (Out-of-Context)\\n\\nLong-term storage for large amounts of information: [...] Additional Resources \\n       Letta Desktop Troubleshooting\\n       ADE Troubleshooting\\n\\nLaunch ADE\\n\\nLight\\n\\nOn this page\\n\\n   The MemGPT Approach to Memory\\n   Types of Memory in Letta\\n   Core Memory (In-Context)\\n   External Memory (Out-of-Context)\\n   Why Agent Memory Matters\\n   Memory Management in Practice\\n\\nStateful Agents\\n\\nAgent Memory\\n============\\n\\nCopy page\\n\\nWhat is agent memory, and how does it work? [...] Automatic management: Agents intelligently decide what to remember\\n   Manual control: Developers can directly view and modify memory blocks\\n   Shared memory: Multiple agents can access common memory blocks\\n   External data sources: Connect agents to files, databases, and APIs\\n\\nMemory blocks are the fundamental units of Letta’s memory system - they can be modified by the agent itself, other agents, or developers through the API.\\n\\nWas this page helpful?\\n\\nYes No\\nThis is lame. We’re better than this (no hate to Langchain, we’re just not in early 2023 anymore).\\n\\nAdvanced Single Agent Memory\\n============================ [...] Vanilla Single Agent Memory\\n===========================')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a entrada inicial para o grafo de workflow\n",
        "inputs = {\n",
        "    \"question\": \"Qual é o modelo mais recente da série Llama da Meta?\",  # Pergunta do usuário\n",
        "    \"max_retries\": 3,  # Número máximo de tentativas para gerar uma resposta válida\n",
        "}\n",
        "\n",
        "# Executa o grafo de forma interativa (streaming), exibindo os eventos à medida que ocorrem\n",
        "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
        "    print(event)  # Imprime cada atualização do estado do grafo durante a execução"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxX_5L6244J9",
        "outputId": "4c70db84-0a34-45f5-bd1a-49cf4461709e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO WEB SEARCH---\n",
            "{'question': 'What are the most recent llama models released?', 'max_retries': 3, 'loop_step': 0}\n",
            "---WEB SEARCH---\n",
            "{'question': 'What are the most recent llama models released?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={}, page_content='Wikipedia\\n\\n# Llama (language model)\\n\\nLlama (Large Language Model Meta AI) is a family of large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 4, released in April 2025. [...] ## Llama 2\\n\\nOn July 18, 2023, in partnership with Microsoft, Meta announced Llama 2 (stylized as LLaMa 2), the next generation of Llama. Meta trained and released Llama 2 in three model sizes: 7, 13, and 70 billion parameters. The model architecture remains largely unchanged from that of Llama 1 models, but 40% more data was used to train the foundational models. [...] On April 18, 2024, Meta released Llama 3 with two sizes: 8B and 70B parameters. The models have been pre-trained on approximately 15 trillion tokens of text gathered from “publicly available sources” with the instruct models fine-tuned on “publicly available instruction datasets, as well as over 10M human-annotated examples\". Meta AI\\'s testing showed in April 2024 that Llama 3 70B was beating Gemini \"Gemini (chatbot)\") Pro 1.5 and Claude \"Claude (language model)\") 3 Sonnet on most benchmarks.\\n# Meta releases Llama 4, a new crop of flagship AI models\\n\\nMeta has released a new collection of AI models, Llama 4, in its Llama family — on a Saturday, no less.\\n\\nThere are three new models in total: Llama 4 Scout, Llama 4 Maverick, and Llama 4 Behemoth. All were trained on “large amounts of unlabeled text, image, and video data” to give them “broad visual understanding,” Meta says. [...] The success of open models from Chinese AI lab DeepSeek, which perform on par or better than Meta’s previous flagship Llama models, reportedly kicked Llama development into overdrive. Meta is said to have scrambled war rooms to decipher how DeepSeek lowered the cost of running and deploying models like R1 and V3. [...] According to Meta’s internal testing, Maverick, which the company says is best for “general assistant and chat” use cases like creative writing, exceeds models such as OpenAI’s GPT-4o and Google’s Gemini 2.0 on certain coding, reasoning, multilingual, long-context, and image benchmarks. However, Maverick doesn’t quite measure up to more capable recent models like Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and OpenAI’s GPT-4.5.\\nLlama 4: The Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding. [...] These Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.\\n\\nHistory:\\n\\nLearn more about the models at \\n\\n### Collections 15\\n\\n#### meta-llama/Llama-4-Scout-17B-16E-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct [...] #### meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\\n\\n#### meta-llama/Llama-3.3-70B-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\\n\\n#### meta-llama/Llama-3.3-70B-Instruct\\n\\n### models 70 Sort:  Recently updated\\n\\n#### meta-llama/Meta-Llama-3-8B-Instruct\\n\\n#### meta-llama/Meta-Llama-3-70B-Instruct\\nWe\\'re introducing Llama 4 Scout and Llama 4 Maverick, the first open-weight natively multimodal models with unprecedented context length support.\\n# Meta releases new AI model Llama 4\\n\\nIllustration shows Meta logo, keyboard and robot hands\\nThe logo of Meta is seen at the entrance of the company\\'s temporary stand ahead of WEF in Davos\\n\\nSign up  here.\\n\\nReporting by Rishabh Jaiswal in Bengaluru; Editing by David Gregorio\\n\\nOur Standards: The Thomson Reuters Trust Principles., opens new tab\\n\\n## Read Next [...] ### Workspace, opens new tab Access unmatched financial data, news and content in a highly-customised workflow experience on desktop, web and mobile.\\n\\nAccess unmatched financial data, news and content in a highly-customised workflow experience on desktop, web and mobile.\\n\\n### Data Catalogue, opens new tab Browse an unrivalled portfolio of real-time and historical market data and insights from worldwide sources and experts. [...] All quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.\\n\\n© 2025 Reuters. All rights reserved')]}\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "{'question': 'What are the most recent llama models released?', 'generation': AIMessage(content='The most recent Llama models released are Llama 4 Scout and Llama 4 Maverick, which are natively multimodal AI models that enable text and multimodal experiences. These models were released as part of the Llama 4 collection, which marks the beginning of a new era for the Llama ecosystem. Llama 4 was released in April 2025, with Llama 4 Scout having 17 billion parameters and 16 experts, and Llama 4 Maverick having 17 billion parameters and 128 experts.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'The most recent Llama models released are Llama 4 Scout and Llama 4 Maverick, which are natively multimodal AI models that enable text and multimodal experiences. These models were released as part of the Llama 4 collection, which marks the beginning of a new era for the Llama ecosystem. Llama 4 was released in April 2025, with Llama 4 Scout having 17 billion parameters and 16 experts, and Llama 4 Maverick having 17 billion parameters and 128 experts.', 'token_usage': {'prompt_tokens': 1254, 'total_tokens': 1364, 'completion_tokens': 110}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run--84b1169f-5ee1-4081-9528-527b8c20e339-0', usage_metadata={'input_tokens': 1254, 'output_tokens': 110, 'total_tokens': 1364}, role='assistant'), 'max_retries': 3, 'loop_step': 1, 'documents': [Document(metadata={}, page_content='Wikipedia\\n\\n# Llama (language model)\\n\\nLlama (Large Language Model Meta AI) is a family of large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 4, released in April 2025. [...] ## Llama 2\\n\\nOn July 18, 2023, in partnership with Microsoft, Meta announced Llama 2 (stylized as LLaMa 2), the next generation of Llama. Meta trained and released Llama 2 in three model sizes: 7, 13, and 70 billion parameters. The model architecture remains largely unchanged from that of Llama 1 models, but 40% more data was used to train the foundational models. [...] On April 18, 2024, Meta released Llama 3 with two sizes: 8B and 70B parameters. The models have been pre-trained on approximately 15 trillion tokens of text gathered from “publicly available sources” with the instruct models fine-tuned on “publicly available instruction datasets, as well as over 10M human-annotated examples\". Meta AI\\'s testing showed in April 2024 that Llama 3 70B was beating Gemini \"Gemini (chatbot)\") Pro 1.5 and Claude \"Claude (language model)\") 3 Sonnet on most benchmarks.\\n# Meta releases Llama 4, a new crop of flagship AI models\\n\\nMeta has released a new collection of AI models, Llama 4, in its Llama family — on a Saturday, no less.\\n\\nThere are three new models in total: Llama 4 Scout, Llama 4 Maverick, and Llama 4 Behemoth. All were trained on “large amounts of unlabeled text, image, and video data” to give them “broad visual understanding,” Meta says. [...] The success of open models from Chinese AI lab DeepSeek, which perform on par or better than Meta’s previous flagship Llama models, reportedly kicked Llama development into overdrive. Meta is said to have scrambled war rooms to decipher how DeepSeek lowered the cost of running and deploying models like R1 and V3. [...] According to Meta’s internal testing, Maverick, which the company says is best for “general assistant and chat” use cases like creative writing, exceeds models such as OpenAI’s GPT-4o and Google’s Gemini 2.0 on certain coding, reasoning, multilingual, long-context, and image benchmarks. However, Maverick doesn’t quite measure up to more capable recent models like Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and OpenAI’s GPT-4.5.\\nLlama 4: The Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding. [...] These Llama 4 models mark the beginning of a new era for the Llama ecosystem. We are launching two efficient models in the Llama 4 series, Llama 4 Scout, a 17 billion parameter model with 16 experts, and Llama 4 Maverick, a 17 billion parameter model with 128 experts.\\n\\nHistory:\\n\\nLearn more about the models at \\n\\n### Collections 15\\n\\n#### meta-llama/Llama-4-Scout-17B-16E-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct [...] #### meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\\n\\n#### meta-llama/Llama-3.3-70B-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E-Instruct\\n\\n#### meta-llama/Llama-4-Scout-17B-16E\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct\\n\\n#### meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\\n\\n#### meta-llama/Llama-3.3-70B-Instruct\\n\\n### models 70 Sort:  Recently updated\\n\\n#### meta-llama/Meta-Llama-3-8B-Instruct\\n\\n#### meta-llama/Meta-Llama-3-70B-Instruct\\nWe\\'re introducing Llama 4 Scout and Llama 4 Maverick, the first open-weight natively multimodal models with unprecedented context length support.\\n# Meta releases new AI model Llama 4\\n\\nIllustration shows Meta logo, keyboard and robot hands\\nThe logo of Meta is seen at the entrance of the company\\'s temporary stand ahead of WEF in Davos\\n\\nSign up  here.\\n\\nReporting by Rishabh Jaiswal in Bengaluru; Editing by David Gregorio\\n\\nOur Standards: The Thomson Reuters Trust Principles., opens new tab\\n\\n## Read Next [...] ### Workspace, opens new tab Access unmatched financial data, news and content in a highly-customised workflow experience on desktop, web and mobile.\\n\\nAccess unmatched financial data, news and content in a highly-customised workflow experience on desktop, web and mobile.\\n\\n### Data Catalogue, opens new tab Browse an unrivalled portfolio of real-time and historical market data and insights from worldwide sources and experts. [...] All quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.\\n\\n© 2025 Reuters. All rights reserved')]}\n"
          ]
        }
      ]
    }
  ]
}